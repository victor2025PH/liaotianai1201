# 分散式部署方案

## 文檔信息

- **版本**: v1.0
- **最後更新**: 2024-12-19
- **適用範圍**: 群組AI系統分散式部署
- **目標**: 每台服務器管理3-5個帳號，確保高可用性與可維護性

---

## 目錄

1. [需求分析](#需求分析)
2. [架構設計](#架構設計)
3. [配置管理](#配置管理)
4. [帳號管理](#帳號管理)
5. [測試與優化](#測試與優化)
6. [故障排查](#故障排查)
7. [性能優化建議](#性能優化建議)
8. [擴展性規劃](#擴展性規劃)

---

## 需求分析

### 1.1 資源需求評估

#### 單個帳號資源需求

| 資源類型 | 最小需求 | 推薦配置 | 說明 |
|---------|---------|---------|------|
| CPU | 0.2 核心 | 0.5 核心 | 消息處理、AI推理 |
| 內存 | 200 MB | 512 MB | Pyrogram Client、對話上下文 |
| 存儲 | 50 MB | 100 MB | Session文件、日誌、緩存 |
| 網絡帶寬 | 1 Mbps | 5 Mbps | Telegram API通信 |
| 磁盤IO | 低 | 中等 | Session文件讀寫、日誌記錄 |

#### 服務器配置建議

**單台服務器（3-5個帳號）**：

| 配置項 | 最小配置 | 推薦配置 | 生產配置 |
|-------|---------|---------|---------|
| CPU | 2 核心 | 4 核心 | 8 核心 |
| 內存 | 4 GB | 8 GB | 16 GB |
| 存儲 | 50 GB | 100 GB | 200 GB SSD |
| 網絡 | 10 Mbps | 50 Mbps | 100 Mbps |
| 操作系統 | Ubuntu 20.04+ | Ubuntu 22.04 LTS | Ubuntu 22.04 LTS |

### 1.2 性能基準測試

#### 測試指標

- **並發消息處理能力**: ≥ 100 消息/分鐘/帳號
- **響應延遲**: ≤ 2 秒（P95）
- **帳號上線率**: ≥ 99%
- **系統穩定性**: 7×24 小時無故障運行

#### 負載測試場景

```yaml
測試場景1: 單帳號基準
  帳號數量: 1
  消息頻率: 10 消息/分鐘
  持續時間: 1 小時
  預期結果: CPU < 20%, 內存 < 512MB

測試場景2: 滿負載測試
  帳號數量: 5
  消息頻率: 50 消息/分鐘/帳號
  持續時間: 2 小時
  預期結果: CPU < 80%, 內存 < 4GB, 無錯誤

測試場景3: 壓力測試
  帳號數量: 5
  消息頻率: 100 消息/分鐘/帳號
  持續時間: 30 分鐘
  預期結果: 系統穩定，響應時間 < 5秒
```

---

## 架構設計

### 2.1 整體架構圖

```
┌─────────────────────────────────────────────────────────────────┐
│                        管理控制層                                │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐        │
│  │  前端管理界面 │  │   API 網關   │  │  配置中心    │        │
│  │  (Next.js)   │  │  (FastAPI)   │  │  (Database)  │        │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘        │
└─────────┼──────────────────┼──────────────────┼───────────────┘
          │                  │                  │
          └──────────────────┼──────────────────┘
                             │
          ┌──────────────────┴──────────────────┐
          │        服務發現與負載均衡              │
          │      (Redis / Consul / etcd)         │
          └──────────────────┬──────────────────┘
                             │
          ┌──────────────────┴──────────────────┐
          │                                      │
    ┌─────▼─────┐                        ┌─────▼─────┐
    │ 服務器節點1 │                        │ 服務器節點N │
    │ (Worker 1)│                        │ (Worker N)│
    ├───────────┤                        ├───────────┤
    │ 帳號 1-3   │                        │ 帳號 M-N   │
    │ Account 1 │                        │ Account M │
    │ Account 2 │                        │ Account M+1│
    │ Account 3 │                        │ ...       │
    └─────┬─────┘                        └─────┬─────┘
          │                                    │
          └────────────┬───────────────────────┘
                       │
            ┌──────────▼──────────┐
            │   Telegram API       │
            │   (外部服務)          │
            └─────────────────────┘
```

### 2.2 節點角色定義

#### 主節點（Master Node）

**職責**：
- 統一管理所有服務器節點
- 帳號分配與負載均衡
- 配置分發與同步
- 監控數據匯總
- API 網關服務

**部署組件**：
- FastAPI 後端服務
- PostgreSQL 數據庫
- Redis 緩存/消息隊列
- 前端管理界面（可選）

#### 工作節點（Worker Node）

**職責**：
- 執行帳號管理任務（3-5個帳號）
- 本地 Session 文件管理
- 消息處理與AI推理
- 本地日誌收集
- 健康狀態上報

**部署組件**：
- Group AI Service（核心服務）
- 本地 Session 存儲
- 本地日誌系統
- 健康檢查服務

### 2.3 節點間通信協議

#### 通信方式

1. **HTTP/REST API**（主節點 ↔ 工作節點）
   - 帳號控制指令
   - 配置同步
   - 狀態查詢

2. **Redis Pub/Sub**（工作節點 ↔ 工作節點）
   - 實時狀態廣播
   - 事件通知
   - 心跳檢測

3. **數據庫同步**（所有節點 ↔ 主節點）
   - 帳號配置持久化
   - 運行日誌存儲
   - 統計數據匯總

#### 通信流程示例

```python
# 主節點分配帳號到工作節點
POST /api/v1/nodes/{node_id}/accounts
{
    "account_ids": ["account_1", "account_2", "account_3"],
    "script_id": "default",
    "group_ids": [123456789]
}

# 工作節點上報狀態
POST /api/v1/nodes/{node_id}/status
{
    "node_id": "worker-01",
    "accounts": [
        {"account_id": "account_1", "status": "online"},
        {"account_id": "account_2", "status": "offline"}
    ],
    "resources": {
        "cpu_usage": 45.2,
        "memory_usage": 2.1,
        "disk_usage": 15.5
    }
}
```

### 2.4 服務發現機制

#### 基於 Redis 的服務發現

```python
# 工作節點註冊
import redis
import json
import time

redis_client = redis.Redis(host='master-node', port=6379, db=0)

def register_worker_node(node_id: str, node_info: dict):
    """註冊工作節點"""
    key = f"worker:nodes:{node_id}"
    node_info['last_heartbeat'] = time.time()
    redis_client.setex(
        key,
        60,  # TTL: 60秒
        json.dumps(node_info)
    )
    redis_client.sadd("worker:nodes:all", node_id)

def heartbeat(node_id: str):
    """發送心跳"""
    while True:
        register_worker_node(node_id, {
            "host": "192.168.1.10",
            "port": 8000,
            "accounts": ["account_1", "account_2"],
            "status": "healthy"
        })
        time.sleep(30)  # 每30秒發送一次
```

---

## 配置管理

### 3.1 操作系統配置

#### Ubuntu 22.04 LTS 基礎配置

```bash
# 1. 更新系統
sudo apt update && sudo apt upgrade -y

# 2. 安裝基礎工具
sudo apt install -y \
    curl \
    wget \
    git \
    vim \
    htop \
    net-tools \
    ufw \
    fail2ban

# 3. 配置防火牆
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 8000/tcp  # API服務
sudo ufw allow 6379/tcp  # Redis（僅內網）
sudo ufw enable

# 4. 配置時區
sudo timedatectl set-timezone Asia/Shanghai

# 5. 配置系統限制
sudo tee -a /etc/security/limits.conf << EOF
* soft nofile 65535
* hard nofile 65535
* soft nproc 65535
* hard nproc 65535
EOF
```

### 3.2 Python 環境配置

#### Python 3.11 安裝與配置

```bash
# 1. 安裝 Python 3.11
sudo apt install -y software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install -y python3.11 python3.11-venv python3.11-dev

# 2. 創建虛擬環境
python3.11 -m venv /opt/group-ai/venv
source /opt/group-ai/venv/bin/activate

# 3. 升級 pip
pip install --upgrade pip setuptools wheel

# 4. 安裝依賴
cd /opt/group-ai
pip install -r requirements.txt
```

#### 依賴庫清單

```txt
# 核心依賴
pyrogram>=2.0.0
tgcrypto>=1.2.5
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.0.0
pydantic-settings>=2.0.0

# 數據庫
sqlalchemy>=2.0.0
alembic>=1.12.0
asyncpg>=0.29.0  # PostgreSQL異步驅動
aiosqlite>=0.19.0  # SQLite異步驅動

# Redis
redis>=5.0.0
hiredis>=2.2.0

# AI相關
openai>=1.0.0
tiktoken>=0.5.0

# 工具庫
python-dotenv>=1.0.0
pyyaml>=6.0
aiofiles>=23.2.0
httpx>=0.25.0

# 監控
prometheus-client>=0.19.0
```

### 3.3 數據庫配置

#### PostgreSQL 安裝與配置

```bash
# 1. 安裝 PostgreSQL
sudo apt install -y postgresql-15 postgresql-contrib-15

# 2. 配置數據庫
sudo -u postgres psql << EOF
CREATE DATABASE group_ai;
CREATE USER group_ai_user WITH PASSWORD 'your_secure_password';
GRANT ALL PRIVILEGES ON DATABASE group_ai TO group_ai_user;
\q
EOF

# 3. 配置連接池
sudo tee -a /etc/postgresql/15/main/postgresql.conf << EOF
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB
maintenance_work_mem = 64MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200
work_mem = 4MB
min_wal_size = 1GB
max_wal_size = 4GB
EOF

# 4. 重啟服務
sudo systemctl restart postgresql
```

#### Redis 安裝與配置

```bash
# 1. 安裝 Redis
sudo apt install -y redis-server

# 2. 配置 Redis
sudo tee -a /etc/redis/redis.conf << EOF
maxmemory 2gb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
EOF

# 3. 配置安全（僅內網訪問）
sudo sed -i 's/bind 127.0.0.1/bind 127.0.0.1 192.168.1.0\/24/' /etc/redis/redis.conf

# 4. 重啟服務
sudo systemctl restart redis-server
```

### 3.4 環境變量配置

#### 主節點環境變量（.env）

```env
# 應用配置
APP_NAME=Group AI Master Node
APP_ENV=production
DEBUG=false

# 數據庫配置
DATABASE_URL=postgresql://group_ai_user:your_secure_password@localhost:5432/group_ai
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=40

# Redis配置
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=

# JWT配置
JWT_SECRET=your_very_secure_jwt_secret_key_min_32_chars
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# Telegram API配置
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash

# OpenAI配置
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-3.5-turbo

# 服務發現配置
SERVICE_DISCOVERY_TYPE=redis
REDIS_SERVICE_DISCOVERY_HOST=localhost
REDIS_SERVICE_DISCOVERY_PORT=6379

# 日誌配置
LOG_LEVEL=INFO
LOG_FILE=/var/log/group-ai/master.log
LOG_MAX_SIZE=100MB
LOG_BACKUP_COUNT=10

# 監控配置
METRICS_ENABLED=true
METRICS_PORT=9090
PROMETHEUS_ENABLED=true
```

#### 工作節點環境變量（.env）

```env
# 應用配置
APP_NAME=Group AI Worker Node
APP_ENV=production
DEBUG=false
NODE_ID=worker-01
NODE_ROLE=worker

# 主節點配置
MASTER_NODE_URL=http://master-node:8000
MASTER_NODE_API_KEY=your_api_key_for_worker

# 數據庫配置（只讀，用於查詢配置）
DATABASE_URL=postgresql://group_ai_user:your_secure_password@master-node:5432/group_ai

# Redis配置（用於服務發現和消息隊列）
REDIS_URL=redis://master-node:6379/0

# Telegram API配置
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash

# OpenAI配置
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-3.5-turbo

# Session文件配置
SESSION_FILES_DIRECTORY=/opt/group-ai/sessions
SESSION_FILES_BACKUP_DIRECTORY=/opt/group-ai/sessions_backup

# 帳號配置
MAX_ACCOUNTS_PER_NODE=5
ACCOUNT_HEALTH_CHECK_INTERVAL=60
ACCOUNT_RECONNECT_DELAY=5
ACCOUNT_MAX_RECONNECT_ATTEMPTS=3

# 日誌配置
LOG_LEVEL=INFO
LOG_FILE=/var/log/group-ai/worker-01.log
LOG_MAX_SIZE=100MB
LOG_BACKUP_COUNT=10

# 監控配置
METRICS_ENABLED=true
METRICS_PORT=9091
HEARTBEAT_INTERVAL=30
```

### 3.5 目錄結構

#### 標準目錄結構

```
/opt/group-ai/
├── admin-backend/          # 後端服務（主節點）
│   ├── app/
│   ├── alembic/
│   ├── requirements.txt
│   └── .env
├── group_ai_service/       # 核心服務（工作節點）
│   ├── account_manager.py
│   ├── script_engine.py
│   ├── dialogue_manager.py
│   └── ...
├── sessions/               # Session文件目錄
│   ├── account_1.session
│   ├── account_2.session
│   └── ...
├── ai_models/              # AI模型和劇本
│   └── group_scripts/
├── logs/                   # 日誌目錄
│   ├── master.log
│   ├── worker-01.log
│   └── ...
├── configs/                # 配置文件
│   ├── node_config.yaml
│   └── account_config.yaml
└── scripts/                # 部署腳本
    ├── deploy.sh
    ├── start.sh
    └── stop.sh
```

---

## 帳號管理

### 4.1 帳號分配策略

#### 策略1: 平均分配

```python
def distribute_accounts_evenly(accounts: List[str], nodes: List[str]) -> Dict[str, List[str]]:
    """平均分配帳號到各個節點"""
    distribution = {node: [] for node in nodes}
    for i, account in enumerate(accounts):
        node = nodes[i % len(nodes)]
        distribution[node].append(account)
    return distribution
```

#### 策略2: 負載均衡分配

```python
def distribute_accounts_by_load(
    accounts: List[str],
    node_loads: Dict[str, float]
) -> Dict[str, List[str]]:
    """根據節點負載分配帳號"""
    distribution = {node: [] for node in node_loads.keys()}
    sorted_nodes = sorted(node_loads.items(), key=lambda x: x[1])
    
    for account in accounts:
        # 選擇負載最低的節點
        node = sorted_nodes[0][0]
        distribution[node].append(account)
        # 更新負載（假設每個帳號增加0.2負載）
        node_loads[node] += 0.2
        sorted_nodes = sorted(node_loads.items(), key=lambda x: x[1])
    
    return distribution
```

#### 策略3: 地理位置分配

```python
def distribute_accounts_by_location(
    accounts: List[dict],
    nodes: List[dict]
) -> Dict[str, List[str]]:
    """根據帳號和節點的地理位置分配"""
    distribution = {node['id']: [] for node in nodes}
    
    for account in accounts:
        # 選擇地理位置最近的節點
        best_node = min(
            nodes,
            key=lambda n: calculate_distance(
                account['location'],
                n['location']
            )
        )
        distribution[best_node['id']].append(account['id'])
    
    return distribution
```

### 4.2 帳號創建流程

#### 完整創建流程

```mermaid
sequenceDiagram
    participant Admin as 管理員
    participant Master as 主節點
    participant Worker as 工作節點
    participant DB as 數據庫
    participant TG as Telegram API

    Admin->>Master: 上傳Session文件
    Master->>Master: 驗證Session文件
    Master->>DB: 保存帳號配置
    Master->>Master: 選擇工作節點
    Master->>Worker: 分配帳號任務
    Worker->>Worker: 加載Session文件
    Worker->>TG: 驗證Session有效性
    TG-->>Worker: 返回驗證結果
    Worker->>DB: 更新帳號狀態
    Worker->>Master: 上報創建結果
    Master->>Admin: 返回創建狀態
```

#### 實現代碼示例

```python
# 主節點：帳號創建API
@app.post("/api/v1/accounts")
async def create_account(
    request: AccountCreateRequest,
    service_manager: ServiceManager = Depends(get_service_manager)
):
    """創建帳號並分配到工作節點"""
    # 1. 驗證Session文件
    session_path = validate_session_file(request.session_file)
    
    # 2. 選擇工作節點
    worker_node = select_worker_node(
        strategy="load_balanced",
        max_accounts_per_node=5
    )
    
    # 3. 保存到數據庫
    account = await db.create_account({
        "account_id": request.account_id,
        "session_file": session_path,
        "node_id": worker_node.id,
        "script_id": request.script_id,
        "status": "pending"
    })
    
    # 4. 分配到工作節點
    result = await worker_node.create_account(account)
    
    # 5. 更新狀態
    if result.success:
        await db.update_account_status(account.id, "online")
    else:
        await db.update_account_status(account.id, "failed")
    
    return result
```

```python
# 工作節點：帳號創建處理
async def create_account_on_worker(account_config: dict):
    """在工作節點上創建帳號"""
    try:
        # 1. 檢查帳號數量限制
        current_count = len(account_manager.list_accounts())
        if current_count >= MAX_ACCOUNTS_PER_NODE:
            raise Exception(f"節點已達到最大帳號數: {MAX_ACCOUNTS_PER_NODE}")
        
        # 2. 下載Session文件（如果不在本地）
        session_file = await download_session_file_if_needed(
            account_config['session_file']
        )
        
        # 3. 添加帳號到AccountManager
        account = await account_manager.add_account(
            account_id=account_config['account_id'],
            session_file=session_file,
            config=AccountConfig(
                account_id=account_config['account_id'],
                session_file=session_file,
                script_id=account_config['script_id'],
                group_ids=account_config.get('group_ids', [])
            )
        )
        
        # 4. 啟動帳號
        await account.start()
        
        # 5. 註冊消息處理器
        await register_message_handlers(account)
        
        return {
            "success": True,
            "account_id": account_config['account_id'],
            "status": "online"
        }
    except Exception as e:
        logger.error(f"創建帳號失敗: {e}")
        return {
            "success": False,
            "account_id": account_config['account_id'],
            "error": str(e)
        }
```

### 4.3 帳號調用流程

#### 消息處理流程

```python
# 工作節點：消息處理
@client.on_message()
async def handle_message(client: Client, message: Message):
    """處理收到的消息"""
    account_id = get_account_id_from_client(client)
    account = account_manager.get_account(account_id)
    
    # 1. 檢查帳號狀態
    if account.status != "online":
        return
    
    # 2. 檢查群組ID（如果配置了）
    if account.config.group_ids and message.chat.id not in account.config.group_ids:
        return
    
    # 3. 檢查關鍵詞過濾
    if not should_process_message(message, account.config):
        return
    
    # 4. 檢查工作時間
    if not is_work_time(account.config):
        return
    
    # 5. 處理消息（AI生成回復）
    response = await dialogue_manager.generate_response(
        account_id=account_id,
        message=message,
        script_id=account.config.script_id
    )
    
    # 6. 發送回復
    if response:
        await client.send_message(
            chat_id=message.chat.id,
            text=response,
            reply_to_message_id=message.id
        )
        
        # 7. 記錄日誌
        await log_message_event(
            account_id=account_id,
            event_type="reply_sent",
            data={"message_id": message.id, "response": response}
        )
```

#### 帳號切換機制

```python
# 工作節點：帳號切換（用於負載均衡）
class AccountSwitcher:
    """帳號切換器 - 實現帳號間的負載均衡"""
    
    def __init__(self, account_manager: AccountManager):
        self.account_manager = account_manager
        self.current_account_index = 0
    
    def get_next_account(self, group_id: int) -> Optional[AccountInstance]:
        """獲取下一個可用帳號"""
        accounts = [
            acc for acc in self.account_manager.list_accounts()
            if acc.status == "online" and self.is_account_available(acc, group_id)
        ]
        
        if not accounts:
            return None
        
        # 輪詢選擇
        account = accounts[self.current_account_index % len(accounts)]
        self.current_account_index += 1
        
        return account
    
    def is_account_available(self, account: AccountInstance, group_id: int) -> bool:
        """檢查帳號是否可用"""
        # 檢查工作時間
        if not is_work_time(account.config):
            return False
        
        # 檢查速率限制
        if not account.rate_limiter.can_send():
            return False
        
        # 檢查群組配置
        if account.config.group_ids and group_id not in account.config.group_ids:
            return False
        
        return True
```

### 4.4 帳號監控與健康檢查

#### 健康檢查實現

```python
# 工作節點：健康檢查服務
class HealthChecker:
    """帳號健康檢查器"""
    
    def __init__(self, account_manager: AccountManager):
        self.account_manager = account_manager
        self.check_interval = 60  # 60秒
    
    async def start(self):
        """啟動健康檢查"""
        while True:
            await self.check_all_accounts()
            await asyncio.sleep(self.check_interval)
    
    async def check_all_accounts(self):
        """檢查所有帳號健康狀態"""
        accounts = self.account_manager.list_accounts()
        
        for account_info in accounts:
            account = self.account_manager.get_account(account_info.account_id)
            
            # 檢查連接狀態
            if not await self.check_connection(account):
                logger.warning(f"帳號 {account.account_id} 連接異常")
                await self.handle_connection_failure(account)
            
            # 檢查資源使用
            resource_usage = await self.check_resources(account)
            if resource_usage['memory'] > 1024 * 1024 * 1024:  # 1GB
                logger.warning(f"帳號 {account.account_id} 內存使用過高")
            
            # 上報狀態到主節點
            await self.report_status(account, resource_usage)
    
    async def check_connection(self, account: AccountInstance) -> bool:
        """檢查帳號連接狀態"""
        try:
            if not account.client.is_connected:
                return False
            
            # 發送一個簡單的API調用來驗證連接
            me = await account.client.get_me()
            return me is not None
        except Exception as e:
            logger.error(f"檢查連接失敗: {e}")
            return False
    
    async def handle_connection_failure(self, account: AccountInstance):
        """處理連接失敗"""
        # 嘗試重連
        for attempt in range(account.config.max_reconnect_attempts):
            try:
                await account.client.connect()
                logger.info(f"帳號 {account.account_id} 重連成功")
                return
            except Exception as e:
                logger.error(f"重連失敗 (嘗試 {attempt + 1}): {e}")
                await asyncio.sleep(account.config.reconnect_delay)
        
        # 重連失敗，標記為離線
        logger.error(f"帳號 {account.account_id} 重連失敗，標記為離線")
        await account.stop()
        await self.notify_master_node(account.account_id, "offline")
```

---

## 測試與優化

### 5.1 部署測試流程

#### 階段1: 單節點測試

```bash
#!/bin/bash
# 單節點測試腳本

echo "=== 階段1: 單節點測試 ==="

# 1. 測試環境配置
echo "1. 檢查Python環境..."
python3.11 --version
pip list | grep pyrogram

# 2. 測試數據庫連接
echo "2. 測試數據庫連接..."
python3.11 -c "from sqlalchemy import create_engine; engine = create_engine('$DATABASE_URL'); conn = engine.connect(); print('DB OK')"

# 3. 測試Redis連接
echo "3. 測試Redis連接..."
python3.11 -c "import redis; r = redis.Redis.from_url('$REDIS_URL'); r.ping(); print('Redis OK')"

# 4. 測試Session文件
echo "4. 測試Session文件..."
ls -la sessions/*.session | head -3

# 5. 啟動單個帳號測試
echo "5. 啟動單個帳號測試..."
python3.11 -m group_ai_service.test_single_account --account-id test_account_1

echo "單節點測試完成"
```

#### 階段2: 多帳號並發測試

```python
# 多帳號並發測試腳本
import asyncio
import time
from group_ai_service.account_manager import AccountManager

async def test_multiple_accounts():
    """測試多個帳號並發運行"""
    account_manager = AccountManager()
    
    # 加載3個帳號
    accounts = ["account_1", "account_2", "account_3"]
    for account_id in accounts:
        await account_manager.add_account(
            account_id=account_id,
            session_file=f"sessions/{account_id}.session",
            config=AccountConfig(account_id=account_id, script_id="default")
        )
        await account_manager.start_account(account_id)
    
    # 運行30分鐘
    start_time = time.time()
    duration = 30 * 60  # 30分鐘
    
    while time.time() - start_time < duration:
        # 檢查所有帳號狀態
        for account_id in accounts:
            account = account_manager.get_account(account_id)
            if account.status != "online":
                print(f"警告: 帳號 {account_id} 狀態異常: {account.status}")
        
        await asyncio.sleep(60)  # 每分鐘檢查一次
    
    print("多帳號測試完成")

if __name__ == "__main__":
    asyncio.run(test_multiple_accounts())
```

#### 階段3: 節點間通信測試

```python
# 節點間通信測試
import requests
import time

def test_node_communication():
    """測試主節點與工作節點通信"""
    master_url = "http://master-node:8000"
    worker_url = "http://worker-01:8000"
    
    # 1. 測試工作節點註冊
    response = requests.post(
        f"{master_url}/api/v1/nodes/register",
        json={
            "node_id": "worker-01",
            "host": "worker-01",
            "port": 8000,
            "max_accounts": 5
        }
    )
    assert response.status_code == 200, "節點註冊失敗"
    
    # 2. 測試帳號分配
    response = requests.post(
        f"{master_url}/api/v1/nodes/worker-01/accounts",
        json={
            "account_ids": ["account_1", "account_2"],
            "script_id": "default"
        }
    )
    assert response.status_code == 200, "帳號分配失敗"
    
    # 3. 測試狀態查詢
    response = requests.get(f"{worker_url}/api/v1/status")
    assert response.status_code == 200, "狀態查詢失敗"
    data = response.json()
    assert data["accounts_count"] == 2, "帳號數量不正確"
    
    print("節點間通信測試通過")

if __name__ == "__main__":
    test_node_communication()
```

### 5.2 性能基準測試

#### 性能測試腳本

```python
# 性能測試腳本
import asyncio
import time
import statistics
from typing import List

class PerformanceTest:
    """性能測試類"""
    
    def __init__(self, account_manager: AccountManager):
        self.account_manager = account_manager
        self.metrics = {
            "message_processing_times": [],
            "response_generation_times": [],
            "api_call_times": []
        }
    
    async def test_message_processing(self, num_messages: int = 100):
        """測試消息處理性能"""
        print(f"開始處理 {num_messages} 條消息...")
        
        start_time = time.time()
        for i in range(num_messages):
            # 模擬消息處理
            process_start = time.time()
            await self.simulate_message_processing()
            process_time = time.time() - process_start
            self.metrics["message_processing_times"].append(process_time)
        
        total_time = time.time() - start_time
        avg_time = statistics.mean(self.metrics["message_processing_times"])
        p95_time = statistics.quantiles(self.metrics["message_processing_times"], n=20)[18]
        
        print(f"總耗時: {total_time:.2f}秒")
        print(f"平均處理時間: {avg_time*1000:.2f}ms")
        print(f"P95處理時間: {p95_time*1000:.2f}ms")
        print(f"吞吐量: {num_messages/total_time:.2f} 消息/秒")
    
    async def simulate_message_processing(self):
        """模擬消息處理"""
        await asyncio.sleep(0.01)  # 模擬處理時間

# 運行性能測試
async def run_performance_tests():
    account_manager = AccountManager()
    tester = PerformanceTest(account_manager)
    
    await tester.test_message_processing(1000)
    
    # 輸出報告
    print("\n=== 性能測試報告 ===")
    print(f"消息處理平均時間: {statistics.mean(tester.metrics['message_processing_times'])*1000:.2f}ms")
    print(f"消息處理P95時間: {statistics.quantiles(tester.metrics['message_processing_times'], n=20)[18]*1000:.2f}ms")
```

### 5.3 性能優化建議

#### 優化1: 連接池優化

```python
# 數據庫連接池優化
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,           # 連接池大小
    max_overflow=40,        # 最大溢出連接數
    pool_pre_ping=True,     # 連接前檢查
    pool_recycle=3600,      # 連接回收時間（1小時）
    echo=False
)
```

#### 優化2: 異步處理優化

```python
# 使用異步隊列處理消息
import asyncio
from asyncio import Queue

class MessageQueue:
    """消息處理隊列"""
    
    def __init__(self, max_size: int = 1000):
        self.queue = Queue(maxsize=max_size)
        self.workers = []
    
    async def start_workers(self, num_workers: int = 5):
        """啟動工作線程"""
        for i in range(num_workers):
            worker = asyncio.create_task(self.worker(f"worker-{i}"))
            self.workers.append(worker)
    
    async def worker(self, worker_id: str):
        """工作線程"""
        while True:
            message = await self.queue.get()
            try:
                await self.process_message(message)
            except Exception as e:
                logger.error(f"處理消息失敗: {e}")
            finally:
                self.queue.task_done()
    
    async def process_message(self, message: dict):
        """處理消息"""
        # 實際處理邏輯
        pass
```

#### 優化3: 緩存優化

```python
# Redis緩存優化
import redis
from functools import wraps

redis_client = redis.Redis(
    host='localhost',
    port=6379,
    decode_responses=True,
    socket_connect_timeout=5,
    socket_keepalive=True
)

def cache_result(ttl: int = 300):
    """結果緩存裝飾器"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache_key = f"{func.__name__}:{args}:{kwargs}"
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            result = await func(*args, **kwargs)
            redis_client.setex(cache_key, ttl, json.dumps(result))
            return result
        return wrapper
    return decorator
```

---

## 故障排查

### 6.1 常見問題與解決方案

#### 問題1: 帳號無法上線

**症狀**：
- 帳號狀態顯示為 "offline" 或 "pending"
- 日誌中出現連接錯誤

**排查步驟**：

```bash
# 1. 檢查Session文件
ls -la sessions/account_*.session
file sessions/account_1.session

# 2. 檢查Telegram API配置
echo $TELEGRAM_API_ID
echo $TELEGRAM_API_HASH

# 3. 檢查網絡連接
curl -I https://api.telegram.org

# 4. 檢查日誌
tail -f /var/log/group-ai/worker-01.log | grep -i "account_1"

# 5. 手動測試Session文件
python3.11 -c "
from pyrogram import Client
from config import API_ID, API_HASH
client = Client('test', api_id=API_ID, api_hash=API_HASH, workdir='sessions')
client.start()
print('Session文件有效')
client.stop()
"
```

**解決方案**：

```python
# 自動重連機制
async def auto_reconnect_account(account_id: str):
    """自動重連帳號"""
    account = account_manager.get_account(account_id)
    
    for attempt in range(3):
        try:
            await account.client.connect()
            if await account.client.get_me():
                logger.info(f"帳號 {account_id} 重連成功")
                return True
        except Exception as e:
            logger.warning(f"重連失敗 (嘗試 {attempt + 1}): {e}")
            await asyncio.sleep(5)
    
    # 重連失敗，嘗試重新驗證
    logger.error(f"帳號 {account_id} 重連失敗，需要重新驗證")
    await account.stop()
    # 通知管理員需要重新驗證Session
    await notify_admin(f"帳號 {account_id} 需要重新驗證Session文件")
    return False
```

#### 問題2: 內存使用過高

**症狀**：
- 系統內存使用率 > 90%
- 帳號響應變慢
- 可能出現 OOM (Out of Memory) 錯誤

**排查步驟**：

```bash
# 1. 檢查內存使用
free -h
ps aux --sort=-%mem | head -10

# 2. 檢查Python進程內存
ps -o pid,vsz,rss,comm -p $(pgrep -f "group_ai")

# 3. 檢查內存洩漏
python3.11 -m memory_profiler group_ai_service/account_manager.py
```

**解決方案**：

```python
# 內存優化：定期清理緩存
class MemoryOptimizer:
    """內存優化器"""
    
    def __init__(self, account_manager: AccountManager):
        self.account_manager = account_manager
        self.cleanup_interval = 3600  # 1小時
    
    async def start(self):
        """啟動內存優化"""
        while True:
            await self.cleanup_memory()
            await asyncio.sleep(self.cleanup_interval)
    
    async def cleanup_memory(self):
        """清理內存"""
        # 1. 清理對話歷史（保留最近100條）
        for account in self.account_manager.list_accounts():
            dialogue_manager = account.dialogue_manager
            if dialogue_manager:
                dialogue_manager.trim_context(max_messages=100)
        
        # 2. 清理Python緩存
        import gc
        gc.collect()
        
        # 3. 清理Redis緩存（過期鍵）
        # Redis會自動清理，這裡只是記錄
        logger.info("內存清理完成")
```

#### 問題3: 節點間通信失敗

**症狀**：
- 主節點無法連接到工作節點
- 工作節點無法上報狀態
- 帳號分配失敗

**排查步驟**：

```bash
# 1. 檢查網絡連接
ping master-node
ping worker-01

# 2. 檢查端口
telnet master-node 8000
telnet worker-01 8000

# 3. 檢查防火牆
sudo ufw status
sudo iptables -L -n

# 4. 檢查服務狀態
curl http://master-node:8000/health
curl http://worker-01:8000/health

# 5. 檢查Redis連接
redis-cli -h master-node ping
```

**解決方案**：

```python
# 通信重試機制
import asyncio
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
async def send_to_master_node(data: dict):
    """發送數據到主節點（帶重試）"""
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                f"{MASTER_NODE_URL}/api/v1/nodes/{NODE_ID}/status",
                json=data
            )
            response.raise_for_status()
            return response.json()
    except Exception as e:
        logger.error(f"發送到主節點失敗: {e}")
        raise
```

### 6.2 日誌分析

#### 日誌級別配置

```python
# 日誌配置
import logging
from logging.handlers import RotatingFileHandler

def setup_logging(log_file: str, log_level: str = "INFO"):
    """設置日誌"""
    logger = logging.getLogger()
    logger.setLevel(getattr(logging, log_level))
    
    # 文件處理器
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=100 * 1024 * 1024,  # 100MB
        backupCount=10
    )
    file_handler.setFormatter(
        logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
    )
    
    # 控制台處理器
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(
        logging.Formatter('%(levelname)s - %(message)s')
    )
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
```

#### 關鍵日誌查詢

```bash
# 查詢錯誤日誌
grep -i "error\|exception\|traceback" /var/log/group-ai/*.log

# 查詢帳號狀態變化
grep "account.*status" /var/log/group-ai/worker-01.log

# 查詢性能問題
grep "slow\|timeout" /var/log/group-ai/*.log

# 實時監控日誌
tail -f /var/log/group-ai/worker-01.log | grep --color -E "ERROR|WARNING|account"
```

### 6.3 監控與告警

#### Prometheus 監控配置

```python
# Prometheus指標收集
from prometheus_client import Counter, Gauge, Histogram, start_http_server

# 定義指標
account_status = Gauge('group_ai_account_status', '帳號狀態', ['account_id', 'status'])
message_processed = Counter('group_ai_messages_processed', '處理的消息數', ['account_id'])
response_time = Histogram('group_ai_response_time', '響應時間', ['account_id'])

# 啟動Prometheus HTTP服務器
start_http_server(9090)

# 更新指標
account_status.labels(account_id='account_1', status='online').set(1)
message_processed.labels(account_id='account_1').inc()
response_time.labels(account_id='account_1').observe(0.5)
```

#### 告警規則配置

```yaml
# Prometheus告警規則 (alerts.yml)
groups:
  - name: group_ai_alerts
    rules:
      - alert: AccountOffline
        expr: group_ai_account_status{status="offline"} > 0
        for: 5m
        annotations:
          summary: "帳號離線"
          description: "帳號 {{ $labels.account_id }} 已離線超過5分鐘"
      
      - alert: HighMemoryUsage
        expr: process_resident_memory_bytes / 1024 / 1024 / 1024 > 4
        for: 10m
        annotations:
          summary: "內存使用過高"
          description: "節點內存使用超過4GB"
      
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, group_ai_response_time) > 5
        for: 5m
        annotations:
          summary: "響應時間過高"
          description: "P95響應時間超過5秒"
```

---

## 性能優化建議

### 7.1 系統級優化

#### 內核參數優化

```bash
# /etc/sysctl.conf
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 30
vm.swappiness = 10
vm.overcommit_memory = 1
```

#### 文件描述符限制

```bash
# /etc/security/limits.conf
* soft nofile 65535
* hard nofile 65535
```

### 7.2 應用級優化

#### 異步處理優化

```python
# 使用asyncio.gather並發處理
async def process_multiple_accounts(account_ids: List[str]):
    """並發處理多個帳號"""
    tasks = [
        process_account(account_id)
        for account_id in account_ids
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results
```

#### 數據庫查詢優化

```python
# 使用批量查詢
async def get_accounts_batch(account_ids: List[str]):
    """批量查詢帳號"""
    async with db_session() as session:
        result = await session.execute(
            select(Account).where(Account.id.in_(account_ids))
        )
        return result.scalars().all()
```

### 7.3 資源管理優化

#### 連接池管理

```python
# 優化連接池配置
engine = create_engine(
    DATABASE_URL,
    pool_size=min(20, MAX_ACCOUNTS_PER_NODE * 2),
    max_overflow=min(40, MAX_ACCOUNTS_PER_NODE * 4),
    pool_pre_ping=True,
    pool_recycle=3600
)
```

---

## 擴展性規劃

### 8.1 水平擴展方案

#### 自動擴容策略

```python
# 自動擴容邏輯
class AutoScaler:
    """自動擴容器"""
    
    def __init__(self):
        self.cpu_threshold = 80  # CPU使用率閾值
        self.memory_threshold = 80  # 內存使用率閾值
        self.account_threshold = 4  # 每節點帳號數閾值
    
    async def check_and_scale(self):
        """檢查並擴容"""
        nodes = await self.get_all_nodes()
        
        for node in nodes:
            metrics = await self.get_node_metrics(node.id)
            
            # 檢查是否需要擴容
            if (metrics['cpu_usage'] > self.cpu_threshold or
                metrics['memory_usage'] > self.memory_threshold or
                metrics['account_count'] >= self.account_threshold):
                
                # 分配帳號到其他節點或創建新節點
                await self.redistribute_accounts(node)
```

### 8.2 未來擴展方向

#### 支持的功能擴展

1. **地理分布部署**
   - 支持多地區部署
   - 根據用戶地理位置選擇最近節點

2. **容器化部署**
   - Docker容器化
   - Kubernetes編排

3. **雲原生架構**
   - 支持雲服務器自動擴縮容
   - 集成雲監控服務

4. **高可用性**
   - 主從切換
   - 數據備份與恢復

---

## 附錄

### A. 部署檢查清單

- [ ] 操作系統配置完成
- [ ] Python環境安裝完成
- [ ] 數據庫配置完成
- [ ] Redis配置完成
- [ ] 環境變量配置完成
- [ ] Session文件準備完成
- [ ] 防火牆規則配置完成
- [ ] 日誌目錄創建完成
- [ ] 服務啟動腳本配置完成
- [ ] 監控系統配置完成
- [ ] 備份策略配置完成

### B. 常用命令參考

```bash
# 啟動服務
systemctl start group-ai-worker

# 停止服務
systemctl stop group-ai-worker

# 查看日誌
journalctl -u group-ai-worker -f

# 重啟服務
systemctl restart group-ai-worker

# 檢查服務狀態
systemctl status group-ai-worker

# 查看資源使用
htop
df -h
free -h
```

### C. 聯繫方式與支持

- **文檔更新**: 請定期檢查本文檔的最新版本
- **問題反饋**: 請通過GitHub Issues或內部工單系統反饋
- **緊急支持**: 聯繫系統管理員

---

**文檔結束**

