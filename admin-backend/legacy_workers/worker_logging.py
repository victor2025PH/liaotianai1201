"""
ğŸ“ æ—¥èªŒæŒä¹…åŒ–æ¨¡çµ„
æ”¯æŒï¼š
- æ–‡ä»¶è¼¸å‡º
- æ—¥èªŒè¼ªè½‰ï¼ˆæŒ‰å¤§å°/æ™‚é–“ï¼‰
- å¤šç´šåˆ¥æ—¥èªŒ
- çµæ§‹åŒ–æ—¥èªŒ
- ç•°æ­¥å¯«å…¥
"""

import os
import sys
import json
import logging
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, field
from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler
from queue import Queue
from threading import Thread
import traceback


# ==================== é…ç½® ====================

@dataclass
class LogConfig:
    """æ—¥èªŒé…ç½®"""
    # åŸºæœ¬è¨­ç½®
    log_dir: str = "./logs"
    log_level: str = "INFO"
    
    # æ–‡ä»¶è¨­ç½®
    log_file: str = "app.log"
    error_file: str = "error.log"
    
    # è¼ªè½‰è¨­ç½®ï¼ˆæŒ‰å¤§å°ï¼‰
    max_bytes: int = 10 * 1024 * 1024  # 10MB
    backup_count: int = 5
    
    # è¼ªè½‰è¨­ç½®ï¼ˆæŒ‰æ™‚é–“ï¼‰
    when: str = "midnight"  # æ¯å¤©åˆå¤œ
    interval: int = 1
    
    # æ ¼å¼è¨­ç½®
    console_format: str = "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    file_format: str = "%(asctime)s [%(levelname)s] %(name)s [%(filename)s:%(lineno)d]: %(message)s"
    date_format: str = "%Y-%m-%d %H:%M:%S"
    
    # JSON æ—¥èªŒ
    json_log_enabled: bool = True
    json_log_file: str = "app.json.log"
    
    # æ€§èƒ½è¨­ç½®
    async_write: bool = True
    buffer_size: int = 100
    
    @classmethod
    def from_env(cls) -> "LogConfig":
        """å¾ç’°å¢ƒè®Šé‡åŠ è¼‰"""
        return cls(
            log_dir=os.getenv("LOG_DIR", "./logs"),
            log_level=os.getenv("LOG_LEVEL", "INFO"),
            max_bytes=int(os.getenv("LOG_MAX_BYTES", str(10 * 1024 * 1024))),
            backup_count=int(os.getenv("LOG_BACKUP_COUNT", "5")),
        )


# ==================== è‡ªå®šç¾© Formatter ====================

class ColoredFormatter(logging.Formatter):
    """å½©è‰²æ—¥èªŒæ ¼å¼åŒ–å™¨ï¼ˆæ§åˆ¶å°ï¼‰"""
    
    COLORS = {
        'DEBUG': '\033[36m',     # é’è‰²
        'INFO': '\033[32m',      # ç¶ è‰²
        'WARNING': '\033[33m',   # é»ƒè‰²
        'ERROR': '\033[31m',     # ç´…è‰²
        'CRITICAL': '\033[35m',  # ç´«è‰²
    }
    RESET = '\033[0m'
    
    def format(self, record):
        # æ·»åŠ é¡è‰²
        levelname = record.levelname
        if levelname in self.COLORS:
            record.levelname = f"{self.COLORS[levelname]}{levelname}{self.RESET}"
        
        return super().format(record)


class JSONFormatter(logging.Formatter):
    """JSON æ ¼å¼åŒ–å™¨"""
    
    def format(self, record):
        log_data = {
            "timestamp": datetime.fromtimestamp(record.created).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # æ·»åŠ é¡å¤–å­—æ®µ
        if hasattr(record, "extra_data"):
            log_data["data"] = record.extra_data
        
        # æ·»åŠ ç•°å¸¸ä¿¡æ¯
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info)
            }
        
        return json.dumps(log_data, ensure_ascii=False)


# ==================== ç•°æ­¥æ—¥èªŒè™•ç†å™¨ ====================

class AsyncFileHandler(logging.Handler):
    """ç•°æ­¥æ–‡ä»¶è™•ç†å™¨"""
    
    def __init__(
        self,
        filename: str,
        max_bytes: int = 10 * 1024 * 1024,
        backup_count: int = 5,
        buffer_size: int = 100
    ):
        super().__init__()
        self.filename = filename
        self.max_bytes = max_bytes
        self.backup_count = backup_count
        self.buffer_size = buffer_size
        
        self._queue: Queue = Queue(maxsize=buffer_size * 10)
        self._handler = RotatingFileHandler(
            filename,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding='utf-8'
        )
        
        # å•Ÿå‹•å¾Œå°å¯«å…¥ç·šç¨‹
        self._running = True
        self._thread = Thread(target=self._write_loop, daemon=True)
        self._thread.start()
    
    def emit(self, record):
        try:
            self._queue.put_nowait(record)
        except:
            pass  # éšŠåˆ—æ»¿æ™‚ä¸Ÿæ£„
    
    def _write_loop(self):
        """å¾Œå°å¯«å…¥å¾ªç’°"""
        while self._running:
            try:
                record = self._queue.get(timeout=1)
                self._handler.emit(record)
            except:
                continue
    
    def close(self):
        self._running = False
        self._thread.join(timeout=5)
        self._handler.close()
        super().close()


# ==================== æ—¥èªŒç®¡ç†å™¨ ====================

class LogManager:
    """æ—¥èªŒç®¡ç†å™¨"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, config: LogConfig = None):
        if self._initialized:
            return
        
        self.config = config or LogConfig.from_env()
        self._handlers: List[logging.Handler] = []
        self._loggers: Dict[str, logging.Logger] = {}
        
        # å‰µå»ºæ—¥èªŒç›®éŒ„
        Path(self.config.log_dir).mkdir(parents=True, exist_ok=True)
        
        # è¨­ç½®æ ¹æ—¥èªŒå™¨
        self._setup_root_logger()
        
        self._initialized = True
    
    def _setup_root_logger(self):
        """è¨­ç½®æ ¹æ—¥èªŒå™¨"""
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, self.config.log_level.upper()))
        
        # æ¸…é™¤ç¾æœ‰è™•ç†å™¨
        root_logger.handlers.clear()
        
        # 1. æ§åˆ¶å°è™•ç†å™¨ï¼ˆå½©è‰²ï¼‰
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.DEBUG)
        console_formatter = ColoredFormatter(
            self.config.console_format,
            datefmt=self.config.date_format
        )
        console_handler.setFormatter(console_formatter)
        root_logger.addHandler(console_handler)
        self._handlers.append(console_handler)
        
        # 2. æ–‡ä»¶è™•ç†å™¨ï¼ˆæŒ‰å¤§å°è¼ªè½‰ï¼‰
        file_path = Path(self.config.log_dir) / self.config.log_file
        if self.config.async_write:
            file_handler = AsyncFileHandler(
                str(file_path),
                max_bytes=self.config.max_bytes,
                backup_count=self.config.backup_count,
                buffer_size=self.config.buffer_size
            )
        else:
            file_handler = RotatingFileHandler(
                str(file_path),
                maxBytes=self.config.max_bytes,
                backupCount=self.config.backup_count,
                encoding='utf-8'
            )
        file_handler.setLevel(logging.DEBUG)
        file_formatter = logging.Formatter(
            self.config.file_format,
            datefmt=self.config.date_format
        )
        file_handler.setFormatter(file_formatter)
        root_logger.addHandler(file_handler)
        self._handlers.append(file_handler)
        
        # 3. éŒ¯èª¤æ—¥èªŒè™•ç†å™¨
        error_path = Path(self.config.log_dir) / self.config.error_file
        error_handler = RotatingFileHandler(
            str(error_path),
            maxBytes=self.config.max_bytes,
            backupCount=self.config.backup_count,
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(file_formatter)
        root_logger.addHandler(error_handler)
        self._handlers.append(error_handler)
        
        # 4. JSON æ—¥èªŒè™•ç†å™¨
        if self.config.json_log_enabled:
            json_path = Path(self.config.log_dir) / self.config.json_log_file
            json_handler = RotatingFileHandler(
                str(json_path),
                maxBytes=self.config.max_bytes,
                backupCount=self.config.backup_count,
                encoding='utf-8'
            )
            json_handler.setLevel(logging.INFO)
            json_handler.setFormatter(JSONFormatter())
            root_logger.addHandler(json_handler)
            self._handlers.append(json_handler)
    
    def get_logger(self, name: str) -> logging.Logger:
        """ç²å–æ—¥èªŒå™¨"""
        if name not in self._loggers:
            self._loggers[name] = logging.getLogger(name)
        return self._loggers[name]
    
    def set_level(self, level: str):
        """è¨­ç½®æ—¥èªŒç´šåˆ¥"""
        log_level = getattr(logging, level.upper())
        logging.getLogger().setLevel(log_level)
    
    def close(self):
        """é—œé–‰æ‰€æœ‰è™•ç†å™¨"""
        for handler in self._handlers:
            handler.close()
        self._handlers.clear()


# ==================== çµæ§‹åŒ–æ—¥èªŒåŠ©æ‰‹ ====================

class StructuredLogger:
    """çµæ§‹åŒ–æ—¥èªŒåŠ©æ‰‹"""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.default_context: Dict[str, Any] = {}
    
    def set_context(self, **kwargs):
        """è¨­ç½®é»˜èªä¸Šä¸‹æ–‡"""
        self.default_context.update(kwargs)
    
    def _log(
        self,
        level: int,
        message: str,
        **extra_data
    ):
        """è¨˜éŒ„çµæ§‹åŒ–æ—¥èªŒ"""
        data = {**self.default_context, **extra_data}
        
        # å‰µå»ºå¸¶é¡å¤–æ•¸æ“šçš„è¨˜éŒ„
        record = self.logger.makeRecord(
            self.logger.name,
            level,
            "(unknown file)",
            0,
            message,
            args=(),
            exc_info=None
        )
        record.extra_data = data
        self.logger.handle(record)
    
    def debug(self, message: str, **extra_data):
        self._log(logging.DEBUG, message, **extra_data)
    
    def info(self, message: str, **extra_data):
        self._log(logging.INFO, message, **extra_data)
    
    def warning(self, message: str, **extra_data):
        self._log(logging.WARNING, message, **extra_data)
    
    def error(self, message: str, **extra_data):
        self._log(logging.ERROR, message, **extra_data)
    
    def critical(self, message: str, **extra_data):
        self._log(logging.CRITICAL, message, **extra_data)
    
    # æ¥­å‹™æ—¥èªŒå¿«æ·æ–¹æ³•
    def user_action(self, user_id: int, action: str, **details):
        """è¨˜éŒ„ç”¨æˆ¶æ“ä½œ"""
        self.info(
            f"ç”¨æˆ¶æ“ä½œ: {action}",
            user_id=user_id,
            action=action,
            **details
        )
    
    def api_call(self, endpoint: str, status: str, duration_ms: float, **details):
        """è¨˜éŒ„ API èª¿ç”¨"""
        self.info(
            f"API èª¿ç”¨: {endpoint} - {status}",
            endpoint=endpoint,
            status=status,
            duration_ms=duration_ms,
            **details
        )
    
    def redpacket_event(self, event_type: str, user_id: int, amount: float, **details):
        """è¨˜éŒ„ç´…åŒ…äº‹ä»¶"""
        self.info(
            f"ç´…åŒ…äº‹ä»¶: {event_type}",
            event_type=event_type,
            user_id=user_id,
            amount=amount,
            **details
        )
    
    def group_event(self, event_type: str, group_id: int, **details):
        """è¨˜éŒ„ç¾¤çµ„äº‹ä»¶"""
        self.info(
            f"ç¾¤çµ„äº‹ä»¶: {event_type}",
            event_type=event_type,
            group_id=group_id,
            **details
        )


# ==================== æ—¥èªŒçµ±è¨ˆ ====================

class LogStats:
    """æ—¥èªŒçµ±è¨ˆ"""
    
    def __init__(self, log_dir: str = "./logs"):
        self.log_dir = Path(log_dir)
    
    def get_log_files(self) -> List[dict]:
        """ç²å–æ—¥èªŒæ–‡ä»¶åˆ—è¡¨"""
        files = []
        
        if not self.log_dir.exists():
            return files
        
        for f in self.log_dir.glob("*.log*"):
            stat = f.stat()
            files.append({
                "name": f.name,
                "size": stat.st_size,
                "size_human": self._format_size(stat.st_size),
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "path": str(f)
            })
        
        return sorted(files, key=lambda x: x["modified"], reverse=True)
    
    def get_total_size(self) -> int:
        """ç²å–ç¸½å¤§å°"""
        if not self.log_dir.exists():
            return 0
        return sum(f.stat().st_size for f in self.log_dir.glob("*.log*"))
    
    def _format_size(self, size: int) -> str:
        """æ ¼å¼åŒ–å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} TB"
    
    def get_error_count(self, hours: int = 24) -> int:
        """ç²å–æœ€è¿‘ N å°æ™‚çš„éŒ¯èª¤æ•¸"""
        error_file = self.log_dir / "error.log"
        if not error_file.exists():
            return 0
        
        count = 0
        cutoff = datetime.now().timestamp() - hours * 3600
        
        try:
            with open(error_file, 'r', encoding='utf-8') as f:
                for line in f:
                    # ç°¡å–®è§£ææ™‚é–“æˆ³
                    try:
                        timestamp_str = line[:19]
                        log_time = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
                        if log_time.timestamp() > cutoff:
                            count += 1
                    except:
                        continue
        except:
            pass
        
        return count
    
    def cleanup_old_logs(self, days: int = 30) -> int:
        """æ¸…ç†èˆŠæ—¥èªŒ"""
        if not self.log_dir.exists():
            return 0
        
        cutoff = datetime.now().timestamp() - days * 86400
        deleted = 0
        
        for f in self.log_dir.glob("*.log*"):
            if f.stat().st_mtime < cutoff:
                f.unlink()
                deleted += 1
        
        return deleted


# ==================== åˆå§‹åŒ–å‡½æ•¸ ====================

def setup_logging(config: LogConfig = None) -> LogManager:
    """
    åˆå§‹åŒ–æ—¥èªŒç³»çµ±
    
    Usage:
        from worker_logging import setup_logging
        
        log_manager = setup_logging()
        logger = log_manager.get_logger("my_module")
        logger.info("Hello World")
    """
    return LogManager(config)


def get_structured_logger(name: str) -> StructuredLogger:
    """
    ç²å–çµæ§‹åŒ–æ—¥èªŒå™¨
    
    Usage:
        from worker_logging import get_structured_logger
        
        logger = get_structured_logger("redpacket")
        logger.redpacket_event("claimed", user_id=123, amount=1.5)
    """
    return StructuredLogger(name)


# å°å‡º
__all__ = [
    "LogConfig",
    "LogManager",
    "StructuredLogger",
    "LogStats",
    "setup_logging",
    "get_structured_logger",
    "ColoredFormatter",
    "JSONFormatter",
    "AsyncFileHandler"
]
