"""
AI ç”Ÿæˆå™¨ - ä½¿ç”¨ AI æ¨¡å‹ç”Ÿæˆå°è©±å›å¾©
æ”¯æŒ OpenAIã€Geminiã€Grok
"""
import logging
from typing import Optional, List, Dict, Any
from datetime import datetime

from pyrogram.types import Message

logger = logging.getLogger(__name__)


class AIGenerator:
    """AI ç”Ÿæˆå™¨ï¼ˆæ”¯æŒå¤šæä¾›å•†ï¼‰"""
    
    def __init__(self, provider: str = "openai", api_key: Optional[str] = None):
        self.provider = provider
        self.api_key = api_key
        self._openai_client = None
        self._gemini_client = None
        self._grok_client = None
        logger.info(f"AIGenerator åˆå§‹åŒ– (provider: {provider})")
    
    async def generate_reply(
        self,
        message: Message,
        context_messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 150,
        system_prompt: Optional[str] = None
    ) -> Optional[str]:
        """ç”Ÿæˆå›å¾©"""
        try:
            if self.provider == "openai":
                return await self._generate_openai(
                    message, context_messages, temperature, max_tokens, system_prompt
                )
            elif self.provider == "gemini":
                return await self._generate_gemini(
                    message, context_messages, temperature, max_tokens, system_prompt
                )
            elif self.provider == "grok":
                return await self._generate_grok(
                    message, context_messages, temperature, max_tokens, system_prompt
                )
            elif self.provider == "mock":
                return await self._generate_mock(message, context_messages)
            else:
                logger.warning(f"æœªçŸ¥çš„ AI æä¾›å•†: {self.provider}")
                return None
        except Exception as e:
            logger.error(f"AI ç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _generate_openai(
        self,
        message: Message,
        context_messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        system_prompt: Optional[str]
    ) -> Optional[str]:
        """ä½¿ç”¨ OpenAI API ç”Ÿæˆå›å¾©"""
        try:
            import openai
            
            if not self.api_key:
                logger.warning("OpenAI API key æœªè¨­ç½®ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
                return await self._generate_mock(message, context_messages)
            
            if not self._openai_client:
                self._openai_client = openai.AsyncOpenAI(api_key=self.api_key)
            
            messages = []
            
            # ç³»çµ±æç¤ºè©
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            else:
                messages.append({
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€å€‹å‹å¥½çš„ Telegram ç¾¤çµ„åŠ©æ‰‹ï¼Œæœƒç”¨è‡ªç„¶ã€å‹å¥½çš„æ–¹å¼å›å¾©æ¶ˆæ¯ã€‚"
                })
            
            # ä¸Šä¸‹æ–‡æ¶ˆæ¯
            for ctx_msg in context_messages:
                messages.append({
                    "role": ctx_msg.get("role", "user"),
                    "content": ctx_msg.get("content", "")
                })
            
            # ç•¶å‰æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": message.text or ""
            })
            
            response = await self._openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            reply = response.choices[0].message.content
            logger.info(f"AI ç”Ÿæˆå›å¾©æˆåŠŸ (é•·åº¦: {len(reply)})")
            return reply
        
        except ImportError:
            logger.warning("openai åº«æœªå®‰è£ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
            return await self._generate_mock(message, context_messages)
        except Exception as e:
            logger.error(f"OpenAI API èª¿ç”¨å¤±æ•—: {e}")
            return await self._generate_mock(message, context_messages)
    
    async def _generate_mock(
        self,
        message: Message,
        context_messages: List[Dict[str, str]]
    ) -> str:
        """æ¨¡æ“¬ AI ç”Ÿæˆï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"""
        text = message.text or ""
        
        # ç°¡å–®çš„é—œéµè©åŒ¹é…å›å¾©
        responses = {
            "ä½ å¥½": ["ä½ å¥½ï¼å¾ˆé«˜èˆˆèªè­˜ä½  ğŸ˜Š", "Hi! Nice to meet you!", "å—¨å‘€ï¼Œæœ€è¿‘éå¾—å¦‚ä½•ï¼Ÿ"],
            "è¬è¬": ["ä¸å®¢æ°£ï¼", "ä¸ç”¨è¬ ğŸ˜Š", "éš¨æ™‚ç‚ºä½ æœå‹™ï¼"],
            "å†è¦‹": ["å†è¦‹ï¼ä¿æŒè¯ç¹«å“¦", "æ‹œæ‹œ ğŸ‘‹", "æœŸå¾…ä¸‹æ¬¡èŠå¤©ï¼"],
        }
        
        for keyword, replies in responses.items():
            if keyword in text:
                import random
                return random.choice(replies)
        
        # é»˜èªå›å¾©
        default_replies = [
            "é€™æ˜¯ä¸€å€‹å¾ˆå¥½çš„è©±é¡Œï¼",
            "æˆ‘ç†è§£ä½ çš„æ„æ€ã€‚",
            "èªªå¾—å°ï¼",
            "å¾ˆæœ‰è¶£çš„æƒ³æ³•ã€‚",
        ]
        import random
        return random.choice(default_replies)
    
    async def _generate_gemini(
        self,
        message: Message,
        context_messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        system_prompt: Optional[str]
    ) -> Optional[str]:
        """ä½¿ç”¨ Google Gemini API ç”Ÿæˆå›å¾©"""
        try:
            import google.generativeai as genai
            
            if not self.api_key:
                logger.warning("Gemini API key æœªè¨­ç½®ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
                return await self._generate_mock(message, context_messages)
            
            if not self._gemini_client:
                genai.configure(api_key=self.api_key)
                self._gemini_client = genai.GenerativeModel('gemini-pro')
            
            # æ„å»ºæç¤ºè¯
            prompt_parts = []
            
            # ç³»ç»Ÿæç¤ºè¯
            if system_prompt:
                prompt_parts.append(system_prompt)
            else:
                prompt_parts.append("ä½ æ˜¯ä¸€å€‹å‹å¥½çš„ Telegram ç¾¤çµ„åŠ©æ‰‹ï¼Œæœƒç”¨è‡ªç„¶ã€å‹å¥½çš„æ–¹å¼å›å¾©æ¶ˆæ¯ã€‚")
            
            # ä¸Šä¸‹æ–‡æ¶ˆæ¯
            for ctx_msg in context_messages:
                role = ctx_msg.get("role", "user")
                content = ctx_msg.get("content", "")
                if role == "user":
                    prompt_parts.append(f"ç”¨æˆ¶: {content}")
                elif role == "assistant":
                    prompt_parts.append(f"åŠ©æ‰‹: {content}")
            
            # ç•¶å‰æ¶ˆæ¯
            prompt_parts.append(f"ç”¨æˆ¶: {message.text or ''}")
            prompt_parts.append("åŠ©æ‰‹:")
            
            full_prompt = "\n".join(prompt_parts)
            
            # ç”Ÿæˆå›å¤
            response = await self._gemini_client.generate_content_async(
                full_prompt,
                generation_config={
                    "temperature": temperature,
                    "max_output_tokens": max_tokens,
                }
            )
            
            reply = response.text
            logger.info(f"Gemini ç”Ÿæˆå›å¾©æˆåŠŸ (é•·åº¦: {len(reply)})")
            return reply
        
        except ImportError:
            logger.warning("google-generativeai åº«æœªå®‰è£ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
            return await self._generate_mock(message, context_messages)
        except Exception as e:
            logger.error(f"Gemini API èª¿ç”¨å¤±æ•—: {e}")
            return await self._generate_mock(message, context_messages)
    
    async def _generate_grok(
        self,
        message: Message,
        context_messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        system_prompt: Optional[str]
    ) -> Optional[str]:
        """ä½¿ç”¨ xAI Grok API ç”Ÿæˆå›å¾©"""
        try:
            import aiohttp
            
            if not self.api_key:
                logger.warning("Grok API key æœªè¨­ç½®ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
                return await self._generate_mock(message, context_messages)
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            
            # ç³»ç»Ÿæç¤ºè¯
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            else:
                messages.append({
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€å€‹å‹å¥½çš„ Telegram ç¾¤çµ„åŠ©æ‰‹ï¼Œæœƒç”¨è‡ªç„¶ã€å‹å¥½çš„æ–¹å¼å›å¾©æ¶ˆæ¯ã€‚"
                })
            
            # ä¸Šä¸‹æ–‡æ¶ˆæ¯
            for ctx_msg in context_messages:
                messages.append({
                    "role": ctx_msg.get("role", "user"),
                    "content": ctx_msg.get("content", "")
                })
            
            # ç•¶å‰æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": message.text or ""
            })
            
            # è°ƒç”¨ Grok API
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.x.ai/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "grok-beta",
                        "messages": messages,
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    },
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        reply = data["choices"][0]["message"]["content"]
                        logger.info(f"Grok ç”Ÿæˆå›å¾©æˆåŠŸ (é•·åº¦: {len(reply)})")
                        return reply
                    else:
                        error_text = await response.text()
                        logger.error(f"Grok API èª¿ç”¨å¤±æ•—: {response.status} - {error_text}")
                        return await self._generate_mock(message, context_messages)
        
        except ImportError:
            logger.warning("aiohttp åº«æœªå®‰è£ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
            return await self._generate_mock(message, context_messages)
        except Exception as e:
            logger.error(f"Grok API èª¿ç”¨å¤±æ•—: {e}")
            return await self._generate_mock(message, context_messages)
    
    def set_provider(self, provider: str, api_key: Optional[str] = None):
        """è¨­ç½® AI æä¾›å•†"""
        self.provider = provider
        self.api_key = api_key
        # é‡ç½®å®¢æˆ·ç«¯ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
        self._openai_client = None
        self._gemini_client = None
        self._grok_client = None
        logger.info(f"AI æä¾›å•†å·²åˆ‡æ›ç‚º: {provider}")


# å…¨å±€å¯¦ä¾‹ï¼ˆå¯é…ç½®ï¼‰
_global_generator: Optional[AIGenerator] = None


def get_ai_generator() -> AIGenerator:
    """ç²å–å…¨å±€ AI ç”Ÿæˆå™¨å¯¦ä¾‹"""
    global _global_generator
    if _global_generator is None:
        # å¾é…ç½®æ–‡ä»¶è®€å–
        try:
            from group_ai_service.config import get_group_ai_config
            config = get_group_ai_config()
            provider = config.ai_provider
            api_key = config.ai_api_key
            
            # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æ²’æœ‰è¨­ç½®ï¼Œå˜—è©¦å¾ç’°å¢ƒè®Šé‡è®€å–ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            if not provider or provider == "mock":
                import os
                env_provider = os.getenv("AI_PROVIDER")
                if env_provider:
                    provider = env_provider
            
            if not api_key:
                import os
                env_api_key = os.getenv("AI_API_KEY")
                if env_api_key:
                    api_key = env_api_key
            
            _global_generator = AIGenerator(provider=provider, api_key=api_key)
            logger.info(f"AI ç”Ÿæˆå™¨å·²å¾é…ç½®æ–‡ä»¶åˆå§‹åŒ– (provider: {provider})")
        except Exception as e:
            logger.warning(f"å¾é…ç½®æ–‡ä»¶è®€å– AI é…ç½®å¤±æ•—: {e}ï¼Œä½¿ç”¨é»˜èªé…ç½®")
            # é™ç´šåˆ°ç’°å¢ƒè®Šé‡
            import os
            provider = os.getenv("AI_PROVIDER", "mock")
            api_key = os.getenv("AI_API_KEY")
            _global_generator = AIGenerator(provider=provider, api_key=api_key)
    return _global_generator

